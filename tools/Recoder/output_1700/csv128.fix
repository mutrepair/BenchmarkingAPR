{
          "0": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((!isDelimiter(lastChar) == isEndOfFile(c))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "1": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(!isDelimiter(lastChar)){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "2": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "3": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(isEndOfFile(lastChar)){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "4": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) != isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "5": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) || !isEndOfFile(lastChar))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "6": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((lastChar == \"null\") || (lastChar == \"null\"))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "7": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) > isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "8": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) || (!isDelimiter(lastChar) == isEndOfFile(c)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "9": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((eol && (((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "10": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "11": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "12": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) >= isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "13": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(emptyLinesIgnored){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "14": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) && !isEndOfFile(lastChar))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "15": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) < isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "16": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((lastChar == \"null\") || !isEndOfFile(lastChar))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "17": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) && (!isDelimiter(lastChar) == isEndOfFile(c)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "18": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((((lastChar == \"null\") || (lastChar == \"null\")) || !isEndOfFile(lastChar))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "19": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(isEndOfFile(c)){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "20": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((!isDelimiter(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "21": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == read(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "22": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(isEncapsulator(c)){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "23": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) || (lastChar == \"null\"))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "24": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!read(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "25": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) || (lastChar == ExtendedBufferedReader.UNDEFINED))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "26": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((lastChar == \"null\")){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "27": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(eol){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "28": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) <= isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "29": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(surroundingSpacesIgnored){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "30": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "31": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((eol && (((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED))) || !isEndOfFile(lastChar))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "32": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == reset(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "33": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) || (((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "34": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) && (!isDelimiter(lastChar) == isEndOfFile(c)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "35": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isWhitespace(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "36": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((lastChar == ExtendedBufferedReader.UNDEFINED)){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "37": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(isDelimiter(c)){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "38": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!reset(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "39": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isWhitespace(c) || (!isDelimiter(lastChar) == isEndOfFile(c)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "40": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) || isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "41": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(EOF) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "42": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isWhitespace(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "43": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == nextToken(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "44": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!readLine(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "45": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isEndOfFile(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "46": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == readLine(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "47": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(EOF)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "48": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!nextToken(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "49": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isEndOfLine(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "50": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(TOKEN) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "51": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(((!isDelimiter(lastChar) || isEndOfFile(c)) || (!isDelimiter(lastChar) == isEndOfFile(c)))){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "52": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isDelimiter(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "53": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!readAgain(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "54": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(c) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "55": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(tkn) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "56": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(eol) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "57": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif(lastChar){\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "58": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(TOKEN)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "59": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(lastChar)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "60": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == readAgain(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "61": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfLine(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "62": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(EORECORD)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "63": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(eol)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "64": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n!isDelimiter(lastChar);\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "65": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(tkn)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "66": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nif((isEndOfFile(lastChar) && (!isDelimiter(lastChar) == isEndOfFile(c)))){            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "67": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\nreturn;\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) {            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "68": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) == isEndOfFile(c))) {            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }"
}