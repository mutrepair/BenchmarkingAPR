{
          "0": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nif(false){                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "1": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nreturn tkn;            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "2": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\ntkn = nextToken(tkn.reset());\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "3": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nc = in.read();\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "4": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nin.readLine();\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "5": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nreturn false;            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "6": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\neol = isEndOfLine(c);\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "7": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nreturn true;            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "8": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "9": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\ntkn.type = EOF;\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "10": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\ntkn.isReady = true;\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "11": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nif(true){                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "12": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nbreak;\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "13": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nif(-false){                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "14": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nsuper.nextToken();\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "15": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nreturn;\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "16": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nif((!isDelimiter(lastChar) && isEndOfFile(c))){\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "17": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nreturn null;            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "18": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nif((!isDelimiter(lastChar) && isEndOfFile(c))){\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n}\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "19": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nif(-1){                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "20": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\ncontinue;\n            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "21": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nreturn this;            if (true) {                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "22": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nbreak;\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "23": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\nreturn;\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "24": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\ncontinue;\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }"
}