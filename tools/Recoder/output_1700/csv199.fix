{
          "0": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(false){                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "1": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(-false){                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "2": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(tkn){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "3": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "4": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(c){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "5": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nreturn null;                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "6": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nreturn tkn;                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "7": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(startLineNumber){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "8": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(-true){                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "9": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(!isWhitespace(c)){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "10": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "11": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(isEndOfFile(c)){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "12": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(isEndOfLine(c)){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "13": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nc = in.read();\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "14": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ntkn.content.append((char)c);\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "15": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ntkn.content.append((char)readEscape(c));\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "16": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(-1){                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "17": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nbreak;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "18": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((\"null\" + getLineNumber())){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "19": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((\"null\" + startLineNumber)){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "20": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ntkn.type = EORECORD;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "21": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ntkn.type = TOKEN;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "22": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(!c){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "23": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(isDelimiter(c)){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "24": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ntkn.type = EOF;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "25": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(TOKEN){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "26": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(EORECORD){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "27": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nreturn;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "28": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ntkn.isReady = true;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "29": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n}\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "30": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(EOF){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "31": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(isEncapsulator(c)){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "32": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c != null)){\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n}\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "33": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nstartLineNumber = false;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "34": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c || ((\"null\" + startLineNumber) + \"null\"))){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "35": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nc = false;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "36": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nint startLineNumber = getLineNumber();\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "37": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber == null)){\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n}\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "38": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ncontinue;\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "39": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif(true){                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "40": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c || c)){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "41": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((tkn != null)){\n                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n}\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "42": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber == null)){\nreturn tkn;}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "43": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber == null)){\nreturn null;}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "44": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nreturn null;}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "45": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nbreak;\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "46": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nreturn tkn;}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "47": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c != null)){\nreturn null;}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "48": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c == null)){\nreturn null;}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "49": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c && (c != null))){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "50": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c || (c != null))){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "51": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c || (c == null))){\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "52": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber == null)){\nreturn false;}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "53": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nreturn;\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "54": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\ncontinue;\n                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "55": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nc = null;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "56": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nc = false;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "57": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nc = true;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "58": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nstartLineNumber = false;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "59": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c != null)){\nc = false;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "60": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((c != null)){\nc = true;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "61": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nstartLineNumber = true;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }",
          "62": "    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n        // save current line\n        int startLineNumber = getLineNumber();\n        // ignore the given delimiter\n        // assert c == delimiter;\n        while (true) {\n            c = in.read();\n            \n            if (isEscape(c)) {\n                tkn.content.append((char) readEscape(c));\n            } else if (isEncapsulator(c)) {\n                if (isEncapsulator(in.lookAhead())) {\n                    // double or escaped encapsulator -> add single encapsulator to token\n                    c = in.read();\n                    tkn.content.append((char) c);\n                } else {\n                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n                    while (true) {\n                        c = in.read();\n                        if (isDelimiter(c)) {\n                            tkn.type = TOKEN;\n                            return tkn;\nif((startLineNumber != null)){\nstartLineNumber = null;\n}                        } else if (true) {                            tkn.type = EOF;\n                            tkn.isReady = true; // There is data at EOF\n                            return tkn;\n                        } else if (isEndOfLine(c)) {\n                            // ok eo token reached\n                            tkn.type = EORECORD;\n                            return tkn;\n                        } else if (!isWhitespace(c)) {\n                            // error invalid char between token and next delimiter\n                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                        }\n                    }\n                }\n            } else if (isEndOfFile(c)) {\n                // error condition (end of file before end of token)\n                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n            } else {\n                // consume character\n                tkn.content.append((char) c);\n            }\n        }\n    }"
}