{
          "0": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(true){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "1": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "2": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(-true){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "3": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(-false){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "4": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((eol && (((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED)))){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "5": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(((lastChar == \"null\") || (lastChar == \"null\"))){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "6": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED))){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "7": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((!isDelimiter(lastChar) && isEndOfFile(c))){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "8": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((lastChar == \"null\")){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "9": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((lastChar == ExtendedBufferedReader.UNDEFINED)){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "10": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nbreak;\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "11": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((((eol && (((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED))) && !isEndOfFile(lastChar)) && !isEndOfFile(lastChar))){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "12": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(isEndOfFile(c)){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "13": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(!true){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "14": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c)))){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "15": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(in.readAgain()){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "16": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(false){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "17": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(-\"null\"){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "18": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(true){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "19": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(\"null\"){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "20": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif((((eol && (((lastChar == \"null\") || (lastChar == \"null\")) || (lastChar == ExtendedBufferedReader.UNDEFINED))) && !isEndOfFile(lastChar)) && (!isDelimiter(lastChar) && isEndOfFile(c)))){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "21": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(null){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "22": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(!false){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "23": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(true){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "24": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(-1){            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "25": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nif(false){\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "26": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\ntkn.type = EOF;\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "27": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nlastChar = c;\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "28": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\neol = isEndOfLine(c);\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "29": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nc = in.read();\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "30": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nc = in.readAgain();\n            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "31": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\ntkn.type = EOF;\n        if (false) {            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "32": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nbreak;\n        if (false) {            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "33": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\nreturn;\n        if (false) {            while (eol\n                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n                    && !isEndOfFile(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }"
}