{
          "0": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nDEFAULT_TABLE_SIZE = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "1": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_TABLE_SIZE = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "2": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_ENTRIES_FOR_REUSE = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "3": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_LENGTH = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "4": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_FOR_REUSE = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "5": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMIN_HASH_SIZE = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "6": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nINITIAL_COLLISION_LEN = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "7": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nLAST_VALID_BUCKET = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "8": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_hashSeed = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "9": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_count = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "10": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_longestCollisionList = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "11": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "12": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHash = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "13": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collCount = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "14": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collEnd = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "15": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "16": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT2 = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "17": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT3 = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "18": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncount = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "19": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "20": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHash = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "21": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollCount = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "22": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollEnd = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "23": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nlongestCollisionList = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "24": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "25": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + 0);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "26": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen - 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "27": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + 2);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "28": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen == 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "29": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen / 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "30": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen * 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "31": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen <= 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "32": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen % 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "33": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + null);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "34": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = _mainHashMask;\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "35": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen >= 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "36": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + false);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "37": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = newLen;\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "38": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen != 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "39": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen > 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "40": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + true);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "41": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nDEFAULT_TABLE_SIZE._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "42": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_TABLE_SIZE._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "43": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_ENTRIES_FOR_REUSE._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "44": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_LENGTH._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "45": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_FOR_REUSE._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "46": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMIN_HASH_SIZE._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "47": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nINITIAL_COLLISION_LEN._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "48": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nLAST_VALID_BUCKET._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "49": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_hashSeed._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "50": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_count._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "51": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_longestCollisionList._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "52": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "53": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHash._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "54": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collCount._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "55": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collEnd._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "56": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "57": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT2._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "58": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT3._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "59": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncount._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "60": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHashMask._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "61": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHash._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "62": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollCount._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "63": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollEnd._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "64": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nlongestCollisionList._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "65": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_length._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "66": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nsize()._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "67": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nbucketCount()._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "68": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nhashSeed()._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "69": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollisionCount()._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "70": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmaxCollisionLength()._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "71": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nfindBestBucket()._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "72": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nlength()._mainHashMask = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "73": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + -1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "74": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nDEFAULT_TABLE_SIZE.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "75": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_TABLE_SIZE.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "76": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_ENTRIES_FOR_REUSE.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "77": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_LENGTH.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "78": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_FOR_REUSE.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "79": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMIN_HASH_SIZE.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "80": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nINITIAL_COLLISION_LEN.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "81": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nLAST_VALID_BUCKET.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "82": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_hashSeed.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "83": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_count.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "84": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_longestCollisionList.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "85": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "86": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHash.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "87": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collCount.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "88": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collEnd.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "89": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "90": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT2.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "91": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT3.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "92": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncount.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "93": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHashMask.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "94": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHash.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "95": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollCount.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "96": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollEnd.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "97": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nlongestCollisionList.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "98": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_length.length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "99": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nsize().length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "100": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nbucketCount().length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "101": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nhashSeed().length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "102": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollisionCount().length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "103": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmaxCollisionLength().length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "104": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nfindBestBucket().length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "105": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nlength().length = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "106": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nreportTooManyCollisions(newLen);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "107": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + \"null\");\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "108": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (_mainHash + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "109": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + newLen);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "110": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "111": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nDEFAULT_TABLE_SIZE.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "112": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_TABLE_SIZE.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "113": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_ENTRIES_FOR_REUSE.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "114": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_LENGTH.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "115": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMAX_COLL_CHAIN_FOR_REUSE.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "116": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMIN_HASH_SIZE.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "117": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nINITIAL_COLLISION_LEN.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "118": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nLAST_VALID_BUCKET.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "119": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_hashSeed.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "120": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_count.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "121": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_longestCollisionList.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "122": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "123": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHash.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "124": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collCount.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "125": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_collEnd.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "126": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "127": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT2.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "128": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nMULT3.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "129": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncount.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "130": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHashMask.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "131": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmainHash.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "132": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollCount.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "133": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollEnd.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "134": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nlongestCollisionList.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "135": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_length.newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "136": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nsize().newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "137": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nbucketCount().newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "138": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nhashSeed().newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "139": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\ncollisionCount().newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "140": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nmaxCollisionLength().newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "141": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nfindBestBucket().newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "142": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nlength().newLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "143": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = reportTooManyCollisions(newLen);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "144": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ( + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "145": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (newLen + _mainHashMask);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "146": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ((newLen + 1) + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "147": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (_mainHashMask + newLen);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "148": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nnewLen = (newLen + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "149": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ((newLen + 1) + 0);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "150": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (_mainHashMask + _mainHashMask);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "151": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "152": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (_mainHashMask + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "153": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (_mainHashMask + 0);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "154": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ((newLen + newLen) + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "155": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ((_mainHashMask + newLen) + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "156": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHash = new int[newLen];\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "157": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ((newLen + _mainHashMask) + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "158": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ((_mainHashMask + _mainHashMask) + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "159": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = ((newLen + newLen) + newLen);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "160": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (((newLen + newLen) + 1) + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "161": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n_mainHashMask = (((newLen + 1) + newLen) + 1);\n        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "162": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\nreturn;\n        _mainHashMask = (newLen + 1);        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }",
          "163": "    private void rehash()\n    {\n        _needRehash = false;        \n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _mainNamesShared = false;\n\n        /* And then we can first deal with the main hash area. Since we\n         * are expanding linearly (double up), we know there'll be no\n         * collisions during this phase.\n         */\n        int[] oldMainHash = _mainHash;\n        int len = oldMainHash.length;\n        int newLen = len+len;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newLen > MAX_TABLE_SIZE) {\n            nukeSymbols();\n            return;\n        }\n        \n        _mainHash = new int[newLen];\n        _mainHashMask = (newLen + 1);        Name[] oldNames = _mainNames;\n        _mainNames = new Name[newLen];\n        int symbolsSeen = 0; // let's do a sanity check\n        for (int i = 0; i < len; ++i) {\n            Name symbol = oldNames[i];\n            if (symbol != null) {\n                ++symbolsSeen;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                _mainNames[ix] = symbol;\n                _mainHash[ix] = hash << 8; // will clear spill index\n            }\n        }\n\n        /* And then the spill area. This may cause collisions, although\n         * not necessarily as many as there were earlier. Let's allocate\n         * same amount of space, however\n         */\n        int oldEnd = _collEnd;\n        if (oldEnd == 0) { // no prior collisions...\n            _longestCollisionList = 0;\n            return;\n        }\n\n        _collCount = 0;\n        _collEnd = 0;\n        _collListShared = false;\n\n        int maxColl = 0;\n        \n        Bucket[] oldBuckets = _collList;\n        _collList = new Bucket[oldBuckets.length];\n        for (int i = 0; i < oldEnd; ++i) {\n            for (Bucket curr = oldBuckets[i]; curr != null; curr = curr._next) {\n                ++symbolsSeen;\n                Name symbol = curr._name;\n                int hash = symbol.hashCode();\n                int ix = (hash & _mainHashMask);\n                int val = _mainHash[ix];\n                if (_mainNames[ix] == null) { // no primary entry?\n                    _mainHash[ix] = (hash << 8);\n                    _mainNames[ix] = symbol;\n                } else { // nope, it's a collision, need to spill over\n                    ++_collCount;\n                    int bucket = val & 0xFF;\n                    if (bucket == 0) { // first spill over?\n                        if (_collEnd <= LAST_VALID_BUCKET) { // yup, still unshared bucket\n                            bucket = _collEnd;\n                            ++_collEnd;\n                            // need to expand?\n                            if (bucket >= _collList.length) {\n                                expandCollision();\n                            }\n                        } else { // nope, have to share... let's find shortest?\n                            bucket = findBestBucket();\n                        }\n                        // Need to mark the entry... and the spill index is 1-based\n                        _mainHash[ix] = (val & ~0xFF) | (bucket + 1);\n                    } else {\n                        --bucket; // 1-based index in value\n                    }\n                    // And then just need to link the new bucket entry in\n                    Bucket newB = new Bucket(symbol, _collList[bucket]);\n                    _collList[bucket] = newB;\n                    maxColl = Math.max(maxColl, newB.length());\n                }\n            } // for (... buckets in the chain ...)\n        } // for (... list of bucket heads ... )\n\n        _longestCollisionList = maxColl;\n        \n        if (symbolsSeen != _count) { // sanity check\n            throw new RuntimeException(\"Internal error: count after rehash \"+symbolsSeen+\"; should be \"+_count);\n        }\n    }"
}