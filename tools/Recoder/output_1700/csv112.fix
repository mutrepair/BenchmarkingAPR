{
          "0": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile((eol && true)){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "1": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !isEndOfFile(lastChar))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "2": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(!isEndOfFile(lastChar)){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "3": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && false) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "4": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile((!isDelimiter(lastChar) && isEndOfFile(c))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "5": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol == true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "6": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !readAgain(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "7": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(isEndOfFile(c)){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "8": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !read(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "9": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\ndo{\n}while((eol && true))\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "10": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol != true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "11": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "12": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile((((eol && true) && !isEndOfFile(lastChar)) && !isEndOfFile(lastChar))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "13": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(emptyLinesIgnored){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "14": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile((isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c)))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "15": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nif((eol && true)){\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "16": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !isEndOfFile(emptyLinesIgnored))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "17": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol > true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "18": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "19": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !isEndOfFile(EOF))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "20": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && isEndOfFile(lastChar))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "21": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !isEndOfFile(tkn))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "22": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(lastChar){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "23": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile((((eol && true) && !isEndOfFile(lastChar)) && (!isDelimiter(lastChar) && isEndOfFile(c)))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "24": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !isEndOfFile(c))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "25": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol >= true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "26": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol < true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "27": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\ndo{\n}while(!isEndOfFile(lastChar))\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "28": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((emptyLinesIgnored && true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "29": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\ndo{\n}while(((eol && true) && !isEndOfFile(lastChar)))\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "30": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((lastChar && true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "31": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile((((eol && true) && isEndOfFile(lastChar)) && !isEndOfFile(lastChar))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "32": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((EOF && true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "33": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol <= true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "34": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && -false) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "35": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nif(!isEndOfFile(lastChar)){\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "36": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((tkn && true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "37": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((c && true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "38": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol || true) && !isEndOfFile(lastChar))){                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "39": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(in.readAgain()){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "40": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nif(emptyLinesIgnored){\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n}\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "41": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\ntkn.type = EOF;\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "42": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nlastChar = c;\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "43": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((eol && true) && !isEndOfFile(lastChar))){\nlastChar = c;\nc = in.read();\neol = isEndOfLine(c);\nc = in.readAgain();\nif(isEndOfFile(c)){\ntkn.type = EOF;\nreturn tkn;\n}\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "44": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nc = in.readAgain();\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "45": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nc = in.read();\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "46": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\neol = isEndOfLine(c);\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "47": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n(;;)                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "48": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nwhile(((((eol && true) && isEndOfFile(lastChar)) && !isEndOfFile(lastChar)) && !isEndOfFile(lastChar))){\n\n}                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "49": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nbreak;\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "50": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }",
          "51": "    Token nextToken(Token tkn) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.readAgain();\n\n        //  read the next char and set eol\n        /* note: unfortunately isEndOfLine may consumes a character silently.\n        *       this has no effect outside of the method. so a simple workaround\n        *       is to call 'readAgain' on the stream...\n        */\n        int c = in.read();\n        boolean eol = isEndOfLine(c);\n        c = in.readAgain();\n\n        //  empty line detection: eol AND (last char was EOL or beginning)\n        if (emptyLinesIgnored) {\nreturn;\n            while (eol\n                    && (true)\n                    && !isEndOfFile(lastChar)) {                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = isEndOfLine(c);\n                c = in.readAgain();\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    tkn.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return tkn;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            tkn.type = EOF;\n            // don't set tkn.isReady here because no content\n            return tkn;\n        }\n\n        //  important: make sure a new char gets consumed in each iteration\n        while (tkn.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (surroundingSpacesIgnored) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = isEndOfLine(c);\n                }\n            }\n            \n            // ok, start of token reached: comment, encapsulated, or token\n            if (isCommentStart(c)) {\n                // ignore everything till end of line and continue (incr linecount)\n                in.readLine();\n                tkn = nextToken(tkn.reset());\n            } else if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                tkn.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                //noop: tkn.content.append(\"\");\n                tkn.type = EORECORD;\n            } else if (isEncapsulator(c)) {\n                // consume encapsulated token\n                encapsulatedTokenLexer(tkn, c);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                //noop: tkn.content.append(\"\");\n                tkn.type = EOF;\n                tkn.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                simpleTokenLexer(tkn, c);\n            }\n        }\n        return tkn;\n    }"
}