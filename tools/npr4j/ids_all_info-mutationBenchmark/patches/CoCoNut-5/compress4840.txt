value +=( bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_SHIFT ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_SHIFT ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_SHIFT ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_SHIFT ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) | BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) | BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) | BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) | BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) | BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) | BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_SHIFT ) | BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_SHIFT ) | BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_SHIFT ) | BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) | BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_SHIFT ) | BYTE_000000_MASK ;
value +=( bytes [ offset - BYTE_2] << BYTE_2_SHIFT ) & BYTE_2_MASK ;
value +=( bytes [ offset - BYTE_0] << BYTE_0_SHIFT ) & BYTE_0_MASK ;
value +=( bytes [ offset - BYTE_4] << BYTE_4_SHIFT ) & BYTE_4_MASK ;
value +=( bytes [ offset - BYTE_24] << BYTE_24_SHIFT ) & BYTE_24_MASK ;
value +=( bytes [ offset - BYTE_00] << BYTE_00_SHIFT ) & BYTE_00_MASK ;
value +=( bytes [ offset - BYTE_16] << BYTE_16_SHIFT ) & BYTE_16_MASK ;
value +=( bytes [ offset - BYTE_3] << BYTE_3_SHIFT ) & BYTE_3_MASK ;
value +=( bytes [ offset - BYTE_0000] << BYTE_0000_SHIFT ) & BYTE_0000_MASK ;
value +=( bytes [ offset - BYTE_1] << BYTE_1_SHIFT ) & BYTE_1_MASK ;
value +=( bytes [ offset - BYTE_8] << BYTE_8_SHIFT ) & BYTE_8_MASK ;
value +=( bytes [ offset - BYTE_000000] << BYTE_000000_SHIFT ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) && BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) && BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) && BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) && BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) && BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) && BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_SHIFT ) && BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_SHIFT ) && BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_SHIFT ) && BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) && BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_SHIFT ) && BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] >> BYTE_2_SHIFT ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] >> BYTE_0_SHIFT ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] >> BYTE_4_SHIFT ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] >> BYTE_24_SHIFT ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] >> BYTE_00_SHIFT ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] >> BYTE_16_SHIFT ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] >> BYTE_3_SHIFT ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] >> BYTE_0000_SHIFT ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] >> BYTE_1_SHIFT ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] >> BYTE_8_SHIFT ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] >> BYTE_000000_SHIFT ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_2_SHIFT ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_0_SHIFT ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_4_SHIFT ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_24_SHIFT ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_00_SHIFT ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_16_SHIFT ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_3_SHIFT ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_0000_SHIFT ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_1_SHIFT ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_000000_SHIFT ) & BYTE_000000_MASK ;
value +=( bytes [ offset / BYTE_2] << BYTE_2_SHIFT ) & BYTE_2_MASK ;
value +=( bytes [ offset / BYTE_0] << BYTE_0_SHIFT ) & BYTE_0_MASK ;
value +=( bytes [ offset / BYTE_4] << BYTE_4_SHIFT ) & BYTE_4_MASK ;
value +=( bytes [ offset / BYTE_24] << BYTE_24_SHIFT ) & BYTE_24_MASK ;
value +=( bytes [ offset / BYTE_00] << BYTE_00_SHIFT ) & BYTE_00_MASK ;
value +=( bytes [ offset / BYTE_16] << BYTE_16_SHIFT ) & BYTE_16_MASK ;
value +=( bytes [ offset / BYTE_3] << BYTE_3_SHIFT ) & BYTE_3_MASK ;
value +=( bytes [ offset / BYTE_0000] << BYTE_0000_SHIFT ) & BYTE_0000_MASK ;
value +=( bytes [ offset / BYTE_1] << BYTE_1_SHIFT ) & BYTE_1_MASK ;
value +=( bytes [ offset / BYTE_8] << BYTE_8_SHIFT ) & BYTE_8_MASK ;
value +=( bytes [ offset / BYTE_000000] << BYTE_000000_SHIFT ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_8_SHIFT ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_8_SHIFT ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_8_SHIFT ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_8_SHIFT ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_8_SHIFT ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_8_SHIFT ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_8_SHIFT ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_8_SHIFT ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_8_SHIFT ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_8_SHIFT ) & BYTE_000000_MASK ;
value += 'License'+ bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) & BYTE_2_MASK ;
value += 'AS IS'+ bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) & BYTE_2_MASK ;
value += 'License'+ bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) & BYTE_0_MASK ;
value += 'AS IS'+ bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) & BYTE_0_MASK ;
value += 'License'+ bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) & BYTE_4_MASK ;
value += 'AS IS'+ bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) & BYTE_4_MASK ;
value += 'License'+ bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) & BYTE_24_MASK ;
value += 'AS IS'+ bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) & BYTE_24_MASK ;
value += 'License'+ bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) & BYTE_00_MASK ;
value += 'AS IS'+ bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) & BYTE_00_MASK ;
value += 'License'+ bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) & BYTE_16_MASK ;
value += 'AS IS'+ bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) & BYTE_16_MASK ;
