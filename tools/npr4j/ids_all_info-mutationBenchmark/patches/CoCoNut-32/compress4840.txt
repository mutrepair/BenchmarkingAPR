value +=( bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_SHIFT ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_SHIFT ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_SHIFT ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_SHIFT ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_SHIFT ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_SHIFT ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_SHIFT ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_SHIFT ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_SHIFT ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_SHIFT ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_SHIFT ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_SHIFT ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_SHIFT ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_SHIFT ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_MASK ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_MASK ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_MASK ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_MASK ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_MASK ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_MASK ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_MASK ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_MASK ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_MASK ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_MASK ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_MASK ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) | BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) | BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) | BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) | BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) | BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) | BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_SHIFT ) | BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_SHIFT ) | BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_SHIFT ) | BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) | BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_SHIFT ) | BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_END ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_END ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_END ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_END ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_END ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_END ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_END ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_END ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_END ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_END ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_END ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_SHIFT ) && BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_SHIFT ) && BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_SHIFT ) && BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_SHIFT ) && BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_SHIFT ) && BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_SHIFT ) && BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_SHIFT ) && BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_SHIFT ) && BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_SHIFT ) && BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_SHIFT ) && BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_SHIFT ) && BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_2) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_0) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_4) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_24) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_00) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_16) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_3) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_0000) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_1) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_8) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_000000) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_Subchain ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_Subchain ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_Subchain ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_Subchain ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_Subchain ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_Subchain ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_Subchain ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_Subchain ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_Subchain ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_Subchain ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_Subchain ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_radius ) & BYTE_2_MASK ;
value +=( bytes [ offset *BYTE_0] << BYTE_0_radius ) & BYTE_0_MASK ;
value +=( bytes [ offset *BYTE_4] << BYTE_4_radius ) & BYTE_4_MASK ;
value +=( bytes [ offset *BYTE_24] << BYTE_24_radius ) & BYTE_24_MASK ;
value +=( bytes [ offset *BYTE_00] << BYTE_00_radius ) & BYTE_00_MASK ;
value +=( bytes [ offset *BYTE_16] << BYTE_16_radius ) & BYTE_16_MASK ;
value +=( bytes [ offset *BYTE_3] << BYTE_3_radius ) & BYTE_3_MASK ;
value +=( bytes [ offset *BYTE_0000] << BYTE_0000_radius ) & BYTE_0000_MASK ;
value +=( bytes [ offset *BYTE_1] << BYTE_1_radius ) & BYTE_1_MASK ;
value +=( bytes [ offset *BYTE_8] << BYTE_8_radius ) & BYTE_8_MASK ;
value +=( bytes [ offset *BYTE_000000] << BYTE_000000_radius ) & BYTE_000000_MASK ;
value +=( bytes [ offset *BYTE_2] << BYTE_2_MARGIN ) & BYTE_2_MASK ;
