## Source Code for CURE's APR model

**To train a GPT-CoNuT model**, run `trainer/gpt_conut_trainer.py`
Some settings you may need to change:
  * vocab_file: the path to the vocabulary file used by the model
  * train_file: the path to the training data
  * valid_file: the path to the validation data
  * gpt_file: the path to the saved GPT PL model
  * hyper_parameter: the hyper-parameter of the model (including the number of encoder/decoder layers, dropout rate, etc.)
  * save_dir: the directory to save the model, default: data/models/

**To train a GPT-FConv model**, run `trainer/gpt_fconv_trainer.py`
Some settings you may need to change:
  * vocab_file: the path to the vocabulary file used by the model
  * train_file: the path to the training data
  * valid_file: the path to the validation data
  * gpt_file: the path to the saved GPT PL model
  * hyper_parameter: the hyper-parameter of the model (including the number of encoder/decoder layers, dropout rate, etc.)
  * save_dir: the directory to save the model, default: data/models/

**To generate patches**, run `tester/generator.py`
Some settings you may need to change:
  * vocab_file: the path to the vocabulary file used by the model
  * input_file: the input data to the model for generating patches, with each line referring to a bug in the following format: `buggy line <CTX> surrounding function`. see `../candidate_patches/QuixBugs/quixbugs_bpe.txt` for reference. 
  * identifier_txt_file: the valid identifiers for each bug, with each line being a list of valid identifiers, identifiers are split by space. see `../candidate_patches/QuixBugs/identifier.txt` for reference
  * identifier_token_file: the tokenized identifiers for each bug, with each line being a list of valid identifiers tokenized by camel letter, underscore, and subword. identifiers are split by `\t`. see `../candidate_patches/QuixBugs/identifier.tokens` for reference
  * output_file: the path to the output result
  * beam_size: the number of candidate patches generated by each model
  * model_file: the path to the saved APR model
`../data/patches/gpt_conut_1.txt` and `../data/patches/gpt_fconv_1.txt` are example candidate patches generated by GPT-CoNuT and GPT-FConv models for QUixBugs benchmark.

**To validate the candidate patches generated by models**, run `validation/rerank.py`, which will rerank the patches generated by all the models and the result will be dumped into `../data/patches/reranked_patches.json`, then run `validation/validate_quixbugs.py` or `validation/validate_defects4j.py`, which will run unit test cases (offered by Defects4J or QuixBugs) to validate the candidate patches. The final result will be dumped into `../data/patches/validated_patches.json`